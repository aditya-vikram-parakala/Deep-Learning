{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FID_DCGAN",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhFs0WibRy9Q",
        "colab_type": "code",
        "outputId": "50d0516f-c4f0-4634-ca19-efafd20e9677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "!pip install tensorflow==1.14\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.16.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.33.6)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.14)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.1.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow==1.14)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (0.16.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVhdqrA-LXEo",
        "colab_type": "code",
        "outputId": "88a5f10f-8797-4afa-e7d8-72cef9dbdbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yelB_GnaLXCD",
        "colab_type": "code",
        "outputId": "32c65412-6a61-4e0a-add1-617995fd38cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.datasets.cifar10 import load_data\n",
        "(trainX, _), (testX, _) = load_data()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wtmNYtCSky4",
        "colab_type": "code",
        "outputId": "ab74ccad-8620-45de-9ae7-2532a2374d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "!pip install scikit-image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.15.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.0.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.3.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (4.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.16.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image) (0.46)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (41.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HKOuszOAo0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.engine import *\n",
        "from keras.legacy import interfaces\n",
        "from keras import activations\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras.utils.generic_utils import func_dump\n",
        "from keras.utils.generic_utils import func_load\n",
        "from keras.utils.generic_utils import deserialize_keras_object\n",
        "from keras.utils.generic_utils import has_arg\n",
        "from keras.utils import conv_utils\n",
        "from keras.legacy import interfaces\n",
        "from keras.layers import Dense, Conv1D, Conv2D, Conv3D, Conv2DTranspose, Embedding\n",
        "import tensorflow as tf\n",
        "\n",
        "class DenseSN(Dense):\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        input_dim = input_shape[-1]\n",
        "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.units,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                                 initializer=initializers.RandomNormal(0, 1),\n",
        "                                 name='sn',\n",
        "                                 trainable=False)\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
        "        self.built = True\n",
        "        \n",
        "    def call(self, inputs, training=None):\n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "        def power_iteration(W, u):\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        #Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        #Calculate Sigma\n",
        "        sigma=K.dot(_v, W_reshaped)\n",
        "        sigma=K.dot(sigma, K.transpose(_u))\n",
        "        #normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        #reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                 W_bar = K.reshape(W_bar, W_shape)  \n",
        "        output = K.dot(inputs, W_bar)\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output \n",
        "        \n",
        "class _ConvSN(Layer):\n",
        "\n",
        "    def __init__(self, rank,\n",
        "                 filters,\n",
        "                 kernel_size,\n",
        "                 strides=1,\n",
        "                 padding='valid',\n",
        "                 data_format=None,\n",
        "                 dilation_rate=1,\n",
        "                 activation=None,\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 spectral_normalization=True,\n",
        "                 **kwargs):\n",
        "        super(_ConvSN, self).__init__(**kwargs)\n",
        "        self.rank = rank\n",
        "        self.filters = filters\n",
        "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n",
        "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
        "        self.padding = conv_utils.normalize_padding(padding)\n",
        "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
        "        self.spectral_normalization = spectral_normalization\n",
        "        self.u = None\n",
        "        \n",
        "    def _l2normalize(self, v, eps=1e-12):\n",
        "        return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "    \n",
        "    def power_iteration(self, u, W):\n",
        "        '''\n",
        "        Accroding the paper, we only need to do power iteration one time.\n",
        "        '''\n",
        "        v = self._l2normalize(K.dot(u, K.transpose(W)))\n",
        "        u = self._l2normalize(K.dot(v, W))\n",
        "        return u, v\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "\n",
        "        #Spectral Normalization\n",
        "        if self.spectral_normalization:\n",
        "            self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                                     initializer=initializers.RandomNormal(0, 1),\n",
        "                                     name='sn',\n",
        "                                     trainable=False)\n",
        "        \n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_dim})\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "        def power_iteration(W, u):\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "        \n",
        "        if self.spectral_normalization:\n",
        "            W_shape = self.kernel.shape.as_list()\n",
        "            #Flatten the Tensor\n",
        "            W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "            _u, _v = power_iteration(W_reshaped, self.u)\n",
        "            #Calculate Sigma\n",
        "            sigma=K.dot(_v, W_reshaped)\n",
        "            sigma=K.dot(sigma, K.transpose(_u))\n",
        "            #normalize it\n",
        "            W_bar = W_reshaped / sigma\n",
        "            #reshape weight tensor\n",
        "            if training in {0, False}:\n",
        "                W_bar = K.reshape(W_bar, W_shape)\n",
        "            else:\n",
        "                with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                    W_bar = K.reshape(W_bar, W_shape)\n",
        "\n",
        "            #update weitht\n",
        "            self.kernel = W_bar\n",
        "        \n",
        "        if self.rank == 1:\n",
        "            outputs = K.conv1d(\n",
        "                inputs,\n",
        "                self.kernel,\n",
        "                strides=self.strides[0],\n",
        "                padding=self.padding,\n",
        "                data_format=self.data_format,\n",
        "                dilation_rate=self.dilation_rate[0])\n",
        "        if self.rank == 2:\n",
        "            outputs = K.conv2d(\n",
        "                inputs,\n",
        "                self.kernel,\n",
        "                strides=self.strides,\n",
        "                padding=self.padding,\n",
        "                data_format=self.data_format,\n",
        "                dilation_rate=self.dilation_rate)\n",
        "        if self.rank == 3:\n",
        "            outputs = K.conv3d(\n",
        "                inputs,\n",
        "                self.kernel,\n",
        "                strides=self.strides,\n",
        "                padding=self.padding,\n",
        "                data_format=self.data_format,\n",
        "                dilation_rate=self.dilation_rate)\n",
        "\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_last':\n",
        "            space = input_shape[1:-1]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_utils.conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding=self.padding,\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
        "        if self.data_format == 'channels_first':\n",
        "            space = input_shape[2:]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_utils.conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding=self.padding,\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            return (input_shape[0], self.filters) + tuple(new_space)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'rank': self.rank,\n",
        "            'filters': self.filters,\n",
        "            'kernel_size': self.kernel_size,\n",
        "            'strides': self.strides,\n",
        "            'padding': self.padding,\n",
        "            'data_format': self.data_format,\n",
        "            'dilation_rate': self.dilation_rate,\n",
        "            'activation': activations.serialize(self.activation),\n",
        "            'use_bias': self.use_bias,\n",
        "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
        "        }\n",
        "        base_config = super(_Conv, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "    \n",
        "class ConvSN2D(Conv2D):\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "            \n",
        "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                         initializer=initializers.RandomNormal(0, 1),\n",
        "                         name='sn',\n",
        "                         trainable=False)\n",
        "        \n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_dim})\n",
        "        self.built = True\n",
        "    def call(self, inputs, training=None):\n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "        def power_iteration(W, u):\n",
        "            #Accroding the paper, we only need to do power iteration one time.\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "        #Spectral Normalization\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        #Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        #Calculate Sigma\n",
        "        sigma=K.dot(_v, W_reshaped)\n",
        "        sigma=K.dot(sigma, K.transpose(_u))\n",
        "        #normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        #reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                W_bar = K.reshape(W_bar, W_shape)\n",
        "                \n",
        "        outputs = K.conv2d(\n",
        "                inputs,\n",
        "                W_bar,\n",
        "                strides=self.strides,\n",
        "                padding=self.padding,\n",
        "                data_format=self.data_format,\n",
        "                dilation_rate=self.dilation_rate)\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs\n",
        "    \n",
        "class ConvSN1D(Conv1D):\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "            \n",
        "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                 initializer=initializers.RandomNormal(0, 1),\n",
        "                 name='sn',\n",
        "                 trainable=False)\n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_dim})\n",
        "        self.built = True\n",
        "        \n",
        "    def call(self, inputs, training=None):\n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "        def power_iteration(W, u):\n",
        "            #Accroding the paper, we only need to do power iteration one time.\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "        #Spectral Normalization\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        #Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        #Calculate Sigma\n",
        "        sigma=K.dot(_v, W_reshaped)\n",
        "        sigma=K.dot(sigma, K.transpose(_u))\n",
        "        #normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        #reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                W_bar = K.reshape(W_bar, W_shape)\n",
        "                \n",
        "        outputs = K.conv1d(\n",
        "                inputs,\n",
        "                W_bar,\n",
        "                strides=self.strides,\n",
        "                padding=self.padding,\n",
        "                data_format=self.data_format,\n",
        "                dilation_rate=self.dilation_rate)\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs\n",
        "\n",
        "class ConvSN3D(Conv3D):    \n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        \n",
        "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                         initializer=initializers.RandomNormal(0, 1),\n",
        "                         name='sn',\n",
        "                         trainable=False)\n",
        "        \n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_dim})\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "        def power_iteration(W, u):\n",
        "            #Accroding the paper, we only need to do power iteration one time.\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "        #Spectral Normalization\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        #Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        #Calculate Sigma\n",
        "        sigma=K.dot(_v, W_reshaped)\n",
        "        sigma=K.dot(sigma, K.transpose(_u))\n",
        "        #normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        #reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                W_bar = K.reshape(W_bar, W_shape)\n",
        "                \n",
        "        outputs = K.conv3d(\n",
        "                inputs,\n",
        "                W_bar,\n",
        "                strides=self.strides,\n",
        "                padding=self.padding,\n",
        "                data_format=self.data_format,\n",
        "                dilation_rate=self.dilation_rate)\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs\n",
        "\n",
        "        \n",
        "class EmbeddingSN(Embedding):\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.embeddings = self.add_weight(\n",
        "            shape=(self.input_dim, self.output_dim),\n",
        "            initializer=self.embeddings_initializer,\n",
        "            name='embeddings',\n",
        "            regularizer=self.embeddings_regularizer,\n",
        "            constraint=self.embeddings_constraint,\n",
        "            dtype=self.dtype)\n",
        "        \n",
        "        self.u = self.add_weight(shape=tuple([1, self.embeddings.shape.as_list()[-1]]),\n",
        "                         initializer=initializers.RandomNormal(0, 1),\n",
        "                         name='sn',\n",
        "                         trainable=False)\n",
        "        \n",
        "        self.built = True\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        if K.dtype(inputs) != 'int32':\n",
        "            inputs = K.cast(inputs, 'int32')\n",
        "            \n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "        def power_iteration(W, u):\n",
        "            #Accroding the paper, we only need to do power iteration one time.\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "        W_shape = self.embeddings.shape.as_list()\n",
        "        #Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.embeddings, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        #Calculate Sigma\n",
        "        sigma=K.dot(_v, W_reshaped)\n",
        "        sigma=K.dot(sigma, K.transpose(_u))\n",
        "        #normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        #reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                W_bar = K.reshape(W_bar, W_shape)\n",
        "        self.embeddings = W_bar\n",
        "            \n",
        "        out = K.gather(self.embeddings, inputs)\n",
        "        return out \n",
        "\n",
        "class ConvSN2DTranspose(Conv2DTranspose):\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if len(input_shape) != 4:\n",
        "            raise ValueError('Inputs should have rank ' +\n",
        "                             str(4) +\n",
        "                             '; Received input shape:', str(input_shape))\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        kernel_shape = self.kernel_size + (self.filters, input_dim)\n",
        "\n",
        "        self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "            \n",
        "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                         initializer=initializers.RandomNormal(0, 1),\n",
        "                         name='sn',\n",
        "                         trainable=False)\n",
        "        \n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n",
        "        self.built = True  \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        input_shape = K.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        if self.data_format == 'channels_first':\n",
        "            h_axis, w_axis = 2, 3\n",
        "        else:\n",
        "            h_axis, w_axis = 1, 2\n",
        "\n",
        "        height, width = input_shape[h_axis], input_shape[w_axis]\n",
        "        kernel_h, kernel_w = self.kernel_size\n",
        "        stride_h, stride_w = self.strides\n",
        "        if self.output_padding is None:\n",
        "            out_pad_h = out_pad_w = None\n",
        "        else:\n",
        "            out_pad_h, out_pad_w = self.output_padding\n",
        "\n",
        "        # Infer the dynamic output shape:\n",
        "        out_height = conv_utils.deconv_length(height,\n",
        "                                              stride_h, kernel_h,\n",
        "                                              self.padding,\n",
        "                                              out_pad_h)\n",
        "        out_width = conv_utils.deconv_length(width,\n",
        "                                             stride_w, kernel_w,\n",
        "                                             self.padding,\n",
        "                                             out_pad_w)\n",
        "        if self.data_format == 'channels_first':\n",
        "            output_shape = (batch_size, self.filters, out_height, out_width)\n",
        "        else:\n",
        "            output_shape = (batch_size, out_height, out_width, self.filters)\n",
        "            \n",
        "        #Spectral Normalization    \n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "        def power_iteration(W, u):\n",
        "            #Accroding the paper, we only need to do power iteration one time.\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        #Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        #Calculate Sigma\n",
        "        sigma=K.dot(_v, W_reshaped)\n",
        "        sigma=K.dot(sigma, K.transpose(_u))\n",
        "        #normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        #reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                W_bar = K.reshape(W_bar, W_shape)\n",
        "        self.kernel = W_bar\n",
        "        \n",
        "        outputs = K.conv2d_transpose(\n",
        "            inputs,\n",
        "            self.kernel,\n",
        "            output_shape,\n",
        "            self.strides,\n",
        "            padding=self.padding,\n",
        "            data_format=self.data_format)\n",
        "\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC21QXn4LS9-",
        "colab_type": "code",
        "outputId": "d302e3c6-b5c5-414d-9349-10e787c4b421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from numpy.random import randn,randint\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from sn import ConvSN2DTranspose\n",
        "BN_MIMENTUM = 0.1\n",
        "BN_EPSILON  = 0.00002\n",
        "\n",
        "\n",
        "def scale_images(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn np.asarray(images_list)\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_images(g_model, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = g_model.predict(x_input)\n",
        "\t# create 'fake' class labels (0)\n",
        "# \ty = zeros((n_samples, 1))\n",
        "\treturn X\n",
        "\n",
        "def define_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(4*4*512, kernel_initializer='glorot_uniform' , input_dim=128))\n",
        "    model.add(Reshape((4,4,512)))\n",
        "    model.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding='same', activation='relu',kernel_initializer='glorot_uniform'))\n",
        "    model.add(BatchNormalization(epsilon=BN_EPSILON, momentum=BN_MIMENTUM))\n",
        "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu',kernel_initializer='glorot_uniform'))\n",
        "    model.add(BatchNormalization(epsilon=BN_EPSILON, momentum=BN_MIMENTUM))\n",
        "    model.add(Conv2DTranspose(64,  kernel_size=4, strides=2, padding='same', activation='relu',kernel_initializer='glorot_uniform'))\n",
        "    model.add(BatchNormalization(epsilon=BN_EPSILON, momentum=BN_MIMENTUM))\n",
        "    model.add(Conv2DTranspose(3,   kernel_size=3, strides=1, padding='same', activation='tanh'))\n",
        "    return model\n",
        "  \n",
        "  \n",
        "mod = keras.applications.inception_v3.InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "\n",
        "def calc_FID(testX,model, n_samples=1000):\n",
        "  # Inception model\n",
        "  rand_idx = randint(0, len(testX), n_samples)\n",
        "  real_samples = testX[rand_idx]\n",
        "  \n",
        "  images1 = real_samples\n",
        "  images1 = images1.astype('float32')\n",
        "  # resize images\n",
        "  images1 = scale_images(images1, (299,299,3))\n",
        "  # scale from [0,255] to [-1,1]\n",
        "  images1 = (images1 - 127.5) / 127.5\n",
        "  fake_images = generate_fake_images(model, 128, n_samples)\n",
        "  images2 = scale_images(fake_images, (299,299,3))\n",
        "  act1 = mod.predict(images1)\n",
        "  act2 = mod.predict(images2)\n",
        "  act_t1 = tf.convert_to_tensor(act1, dtype=tf.float32)\n",
        "  act_t2 = tf.convert_to_tensor(act2, dtype=tf.float32)\n",
        "  a = tf.contrib.gan.eval.frechet_classifier_distance_from_activations(\n",
        "      act_t1,\n",
        "      act_t2\n",
        "  )\n",
        "  with tf.Session() as sess:\n",
        "    FID_score = a.eval()\n",
        "  print('FID SCORE:', FID_score)\n",
        "  return FID_score\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XRHlac7MCld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fid_list = []\n",
        "models_list = ['generator_model_020.h5','generator_model_040.h5','generator_model_060.h5','cifar10_gan_BCEgenerator_model_080.h5','cifar10_gan_BCEgenerator_model_100.h5','cifar10_gan_BCEgenerator_model_120.h5']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJjSK0lkMCoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "gen_model = define_generator(128)\n",
        "\n",
        "for md in models_list:\n",
        "  g_model = load_model(md)\n",
        "  temp = calc_FID(testX,g_model)\n",
        "  fid_list.append(temp)\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKeHK-moMCq-",
        "colab_type": "code",
        "outputId": "fbae9f8d-d1e4-4a3b-87a4-cf09505901b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(fid_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[109.25747, 96.22475, 90.230095, 83.966255, 81.01923, 77.05386]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWXXIyetMCuT",
        "colab_type": "code",
        "outputId": "3fc3fabe-3985-4786-ee2b-a08c74326923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot([20,40,60,80,100,120],fid_list)\n",
        "plt.xlabel('No of Epochs')\n",
        "plt.ylabel('FID-scores')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86VXmvqzEEYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcoT-nlOB4Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}